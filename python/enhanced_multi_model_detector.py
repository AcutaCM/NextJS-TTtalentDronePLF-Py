#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆå¤šæ¨¡å‹æ£€æµ‹å™¨
ä¼˜åŒ–ç®—æ³•æ•ˆç‡ã€å†…å­˜ç®¡ç†å’Œæ£€æµ‹æ€§èƒ½
"""

import os
import json
import time
import threading
import numpy as np
from datetime import datetime
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Any, Union
from enum import Enum
import logging
from collections import deque, defaultdict
import weakref
import gc

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# YOLOå¯¼å…¥æ£€æŸ¥
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
    logger.info("âœ… YOLOåº“åŠ è½½æˆåŠŸ")
except ImportError as e:
    YOLO_AVAILABLE = False
    logger.error(f"âœ— YOLOåº“å¯¼å…¥å¤±è´¥: {e}")

# OpenCVå¯¼å…¥æ£€æŸ¥
try:
    import cv2
    CV2_AVAILABLE = True
    logger.info("âœ… OpenCVåº“åŠ è½½æˆåŠŸ")
except ImportError:
    CV2_AVAILABLE = False
    logger.error("âœ— OpenCVåº“æœªå®‰è£…ï¼")


class ModelType(Enum):
    """æ¨¡å‹ç±»å‹æšä¸¾"""
    MATURITY = "maturity"
    DISEASE = "disease"
    GENERAL = "general"


class DetectionStatus(Enum):
    """æ£€æµ‹çŠ¶æ€æšä¸¾"""
    SUCCESS = "success"
    FAILED = "failed"
    SKIPPED = "skipped"
    CACHED = "cached"


@dataclass
class Detection:
    """æ£€æµ‹ç»“æœæ•°æ®ç±»"""
    bbox: List[float]  # [x1, y1, x2, y2]
    confidence: float
    class_name: str
    model_type: ModelType
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    track_id: Optional[int] = None
    additional_info: Dict[str, Any] = field(default_factory=dict)


@dataclass
class TrackedObject:
    """è·Ÿè¸ªå¯¹è±¡æ•°æ®ç±»"""
    track_id: int
    detections: deque = field(default_factory=lambda: deque(maxlen=10))
    last_seen: float = field(default_factory=time.time)
    confidence_history: deque = field(default_factory=lambda: deque(maxlen=5))
    position_history: deque = field(default_factory=lambda: deque(maxlen=5))
    stable_count: int = 0
    
    def update(self, detection: Detection):
        """æ›´æ–°è·Ÿè¸ªå¯¹è±¡"""
        self.detections.append(detection)
        self.last_seen = time.time()
        self.confidence_history.append(detection.confidence)
        
        # è®¡ç®—ä¸­å¿ƒç‚¹
        bbox = detection.bbox
        center = [(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2]
        self.position_history.append(center)
        
        # æ›´æ–°ç¨³å®šè®¡æ•°
        if len(self.confidence_history) >= 3:
            recent_confidences = list(self.confidence_history)[-3:]
            if all(c > 0.7 for c in recent_confidences):
                self.stable_count += 1
            else:
                self.stable_count = max(0, self.stable_count - 1)
    
    @property
    def is_stable(self) -> bool:
        """åˆ¤æ–­å¯¹è±¡æ˜¯å¦ç¨³å®š"""
        return self.stable_count >= 3
    
    @property
    def avg_confidence(self) -> float:
        """å¹³å‡ç½®ä¿¡åº¦"""
        if not self.confidence_history:
            return 0.0
        return sum(self.confidence_history) / len(self.confidence_history)


class ModelConfig:
    """æ¨¡å‹é…ç½®ç±»"""
    
    def __init__(self, model_path: str, model_type: ModelType):
        self.model_path = model_path
        self.model_type = model_type
        self.model = None
        self.is_loaded = False
        self.load_time = 0
        self.inference_count = 0
        self.total_inference_time = 0
        
        # æ€§èƒ½ä¼˜åŒ–å‚æ•°
        self.confidence_threshold = 0.5
        self.iou_threshold = 0.45
        self.max_detections = 100
        self.input_size = (640, 640)
        
        # ç¼“å­˜è®¾ç½®
        self.enable_cache = True
        self.cache_size = 50
        self.result_cache = {}
        
    def load_model(self) -> bool:
        """åŠ è½½æ¨¡å‹"""
        try:
            if not YOLO_AVAILABLE:
                logger.error("YOLOåº“ä¸å¯ç”¨ï¼Œæ— æ³•åŠ è½½æ¨¡å‹")
                return False
            
            if not os.path.exists(self.model_path):
                logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
                return False
            
            start_time = time.time()
            self.model = YOLO(self.model_path)
            
            # é¢„çƒ­æ¨¡å‹
            dummy_input = np.zeros((640, 640, 3), dtype=np.uint8)
            _ = self.model(dummy_input, verbose=False)
            
            self.load_time = time.time() - start_time
            self.is_loaded = True
            
            logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {os.path.basename(self.model_path)} ({self.load_time:.2f}s)")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ {self.model_path}: {e}")
            return False
    
    def predict(self, image: np.ndarray, enable_cache: bool = True) -> List[Detection]:
        """æ‰§è¡Œé¢„æµ‹"""
        if not self.is_loaded or self.model is None:
            return []
        
        try:
            # ç¼“å­˜æ£€æŸ¥
            if enable_cache and self.enable_cache:
                cache_key = self._generate_cache_key(image)
                if cache_key in self.result_cache:
                    return self.result_cache[cache_key]
            
            start_time = time.time()
            
            # æ‰§è¡Œæ¨ç†
            results = self.model(
                image,
                conf=self.confidence_threshold,
                iou=self.iou_threshold,
                max_det=self.max_detections,
                verbose=False
            )
            
            inference_time = time.time() - start_time
            self.inference_count += 1
            self.total_inference_time += inference_time
            
            # è§£æç»“æœ
            detections = self._parse_results(results)
            
            # ç¼“å­˜ç»“æœ
            if enable_cache and self.enable_cache and len(self.result_cache) < self.cache_size:
                self.result_cache[cache_key] = detections
            
            return detections
            
        except Exception as e:
            logger.error(f"æ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
            return []
    
    def _generate_cache_key(self, image: np.ndarray) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # ä½¿ç”¨å›¾åƒçš„ç®€å•å“ˆå¸Œä½œä¸ºç¼“å­˜é”®
        return str(hash(image.tobytes()))
    
    def _parse_results(self, results) -> List[Detection]:
        """è§£æYOLOç»“æœ"""
        detections = []
        
        try:
            for result in results:
                if result.boxes is not None:
                    boxes = result.boxes.xyxy.cpu().numpy()
                    confidences = result.boxes.conf.cpu().numpy()
                    classes = result.boxes.cls.cpu().numpy()
                    
                    for i in range(len(boxes)):
                        bbox = boxes[i].tolist()
                        confidence = float(confidences[i])
                        class_id = int(classes[i])
                        
                        # è·å–ç±»å
                        class_name = result.names.get(class_id, f"class_{class_id}")
                        
                        detection = Detection(
                            bbox=bbox,
                            confidence=confidence,
                            class_name=class_name,
                            model_type=self.model_type
                        )
                        detections.append(detection)
            
        except Exception as e:
            logger.error(f"ç»“æœè§£æå¤±è´¥: {e}")
        
        return detections
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.result_cache.clear()
    
    @property
    def avg_inference_time(self) -> float:
        """å¹³å‡æ¨ç†æ—¶é—´"""
        if self.inference_count == 0:
            return 0.0
        return self.total_inference_time / self.inference_count


class EnhancedMultiModelDetector:
    """å¢å¼ºç‰ˆå¤šæ¨¡å‹æ£€æµ‹å™¨"""
    
    def __init__(self, models_config: Dict[str, str]):
        """
        åˆå§‹åŒ–å¤šæ¨¡å‹æ£€æµ‹å™¨
        
        Args:
            models_config: æ¨¡å‹é…ç½®å­—å…¸ {model_name: model_path}
        """
        self.models: Dict[str, ModelConfig] = {}
        self.tracking_objects: Dict[int, TrackedObject] = {}
        self.next_track_id = 1
        
        # æ€§èƒ½ä¼˜åŒ–å‚æ•°
        self.detection_interval = 0.1  # æ£€æµ‹é—´éš”
        self.track_timeout = 3.0  # è·Ÿè¸ªè¶…æ—¶
        self.distance_threshold = 50  # è·ç¦»é˜ˆå€¼
        self.max_frame_skip = 5  # æœ€å¤§è·³å¸§æ•°
        self.frame_skip_counter = 0
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.performance_stats = {
            'total_detections': 0,
            'successful_detections': 0,
            'failed_detections': 0,
            'cached_detections': 0,
            'avg_processing_time': 0,
            'memory_usage': 0
        }
        
        # çº¿ç¨‹å®‰å…¨é”
        self.lock = threading.RLock()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._initialize_models(models_config)
        
        # å¯åŠ¨æ¸…ç†çº¿ç¨‹
        self._start_cleanup_thread()
    
    def _initialize_models(self, models_config: Dict[str, str]):
        """åˆå§‹åŒ–æ¨¡å‹"""
        logger.info("ğŸ”§ åˆå§‹åŒ–å¢å¼ºç‰ˆå¤šæ¨¡å‹æ£€æµ‹å™¨...")
        
        model_type_mapping = {
            'best.pt': ModelType.GENERAL,
            'strawberry_yolov11.pt': ModelType.MATURITY,
            'disease_model.pt': ModelType.DISEASE
        }
        
        for model_name, model_path in models_config.items():
            try:
                # ç¡®å®šæ¨¡å‹ç±»å‹
                model_type = ModelType.GENERAL
                for key, mtype in model_type_mapping.items():
                    if key in model_name:
                        model_type = mtype
                        break
                
                # åˆ›å»ºæ¨¡å‹é…ç½®
                config = ModelConfig(model_path, model_type)
                
                # åŠ è½½æ¨¡å‹
                if config.load_model():
                    self.models[model_name] = config
                    logger.info(f"âœ… æ¨¡å‹ {model_name} åˆå§‹åŒ–æˆåŠŸ")
                else:
                    logger.warning(f"âš ï¸ æ¨¡å‹ {model_name} åˆå§‹åŒ–å¤±è´¥")
                    
            except Exception as e:
                logger.error(f"âŒ æ¨¡å‹ {model_name} åˆå§‹åŒ–å¼‚å¸¸: {e}")
        
        logger.info(f"ğŸ¯ æˆåŠŸåŠ è½½ {len(self.models)} ä¸ªæ¨¡å‹")
    
    def _start_cleanup_thread(self):
        """å¯åŠ¨æ¸…ç†çº¿ç¨‹"""
        def cleanup_worker():
            while True:
                try:
                    self._cleanup_expired_tracks()
                    self._cleanup_model_caches()
                    time.sleep(5.0)  # æ¯5ç§’æ¸…ç†ä¸€æ¬¡
                except Exception as e:
                    logger.error(f"æ¸…ç†çº¿ç¨‹é”™è¯¯: {e}")
        
        cleanup_thread = threading.Thread(
            target=cleanup_worker,
            daemon=True,
            name="ModelCleanupThread"
        )
        cleanup_thread.start()
    
    def _cleanup_expired_tracks(self):
        """æ¸…ç†è¿‡æœŸçš„è·Ÿè¸ªå¯¹è±¡"""
        with self.lock:
            current_time = time.time()
            expired_ids = []
            
            for track_id, tracked_obj in self.tracking_objects.items():
                if current_time - tracked_obj.last_seen > self.track_timeout:
                    expired_ids.append(track_id)
            
            for track_id in expired_ids:
                del self.tracking_objects[track_id]
            
            if expired_ids:
                logger.debug(f"æ¸…ç†äº† {len(expired_ids)} ä¸ªè¿‡æœŸè·Ÿè¸ªå¯¹è±¡")
    
    def _cleanup_model_caches(self):
        """æ¸…ç†æ¨¡å‹ç¼“å­˜"""
        for model_config in self.models.values():
            if len(model_config.result_cache) > model_config.cache_size:
                # æ¸…ç†ä¸€åŠçš„ç¼“å­˜
                items_to_remove = len(model_config.result_cache) // 2
                keys_to_remove = list(model_config.result_cache.keys())[:items_to_remove]
                
                for key in keys_to_remove:
                    model_config.result_cache.pop(key, None)
    
    def set_detection_parameters(self, **kwargs):
        """è®¾ç½®æ£€æµ‹å‚æ•°"""
        with self.lock:
            if 'detection_interval' in kwargs:
                self.detection_interval = kwargs['detection_interval']
            if 'track_timeout' in kwargs:
                self.track_timeout = kwargs['track_timeout']
            if 'distance_threshold' in kwargs:
                self.distance_threshold = kwargs['distance_threshold']
            if 'max_frame_skip' in kwargs:
                self.max_frame_skip = kwargs['max_frame_skip']
            
            logger.info(f"æ£€æµ‹å‚æ•°å·²æ›´æ–°: {kwargs}")
    
    def detect_multi_model(self, 
                          image: np.ndarray, 
                          enable_maturity: bool = True,
                          enable_disease: bool = True,
                          enable_tracking: bool = True,
                          force_detection: bool = False) -> List[Detection]:
        """
        å¤šæ¨¡å‹æ£€æµ‹
        
        Args:
            image: è¾“å…¥å›¾åƒ
            enable_maturity: å¯ç”¨æˆç†Ÿåº¦æ£€æµ‹
            enable_disease: å¯ç”¨ç—…å®³æ£€æµ‹
            enable_tracking: å¯ç”¨ç›®æ ‡è·Ÿè¸ª
            force_detection: å¼ºåˆ¶æ£€æµ‹ï¼ˆå¿½ç•¥è·³å¸§ï¼‰
            
        Returns:
            æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        start_time = time.time()
        
        try:
            with self.lock:
                # æ™ºèƒ½è·³å¸§
                if not force_detection:
                    self.frame_skip_counter += 1
                    if self.frame_skip_counter < self.max_frame_skip:
                        self.performance_stats['total_detections'] += 1
                        return self._get_cached_detections()
                    self.frame_skip_counter = 0
                
                # æ‰§è¡Œæ£€æµ‹
                all_detections = []
                
                # æˆç†Ÿåº¦æ£€æµ‹
                if enable_maturity:
                    maturity_detections = self._detect_with_model_type(image, ModelType.MATURITY)
                    all_detections.extend(maturity_detections)
                
                # ç—…å®³æ£€æµ‹
                if enable_disease:
                    disease_detections = self._detect_with_model_type(image, ModelType.DISEASE)
                    all_detections.extend(disease_detections)
                
                # é€šç”¨æ£€æµ‹
                general_detections = self._detect_with_model_type(image, ModelType.GENERAL)
                all_detections.extend(general_detections)
                
                # éæœ€å¤§æŠ‘åˆ¶
                filtered_detections = self._apply_nms(all_detections)
                
                # ç›®æ ‡è·Ÿè¸ª
                if enable_tracking:
                    tracked_detections = self._update_tracking(filtered_detections)
                else:
                    tracked_detections = filtered_detections
                
                # æ›´æ–°ç»Ÿè®¡
                processing_time = time.time() - start_time
                self._update_performance_stats(len(tracked_detections), processing_time, True)
                
                return tracked_detections
                
        except Exception as e:
            logger.error(f"å¤šæ¨¡å‹æ£€æµ‹å¤±è´¥: {e}")
            self._update_performance_stats(0, time.time() - start_time, False)
            return []
    
    def _detect_with_model_type(self, image: np.ndarray, model_type: ModelType) -> List[Detection]:
        """ä½¿ç”¨æŒ‡å®šç±»å‹çš„æ¨¡å‹è¿›è¡Œæ£€æµ‹"""
        detections = []
        
        for model_name, model_config in self.models.items():
            if model_config.model_type == model_type:
                model_detections = model_config.predict(image)
                detections.extend(model_detections)
        
        return detections
    
    def _apply_nms(self, detections: List[Detection], iou_threshold: float = 0.5) -> List[Detection]:
        """åº”ç”¨éæœ€å¤§æŠ‘åˆ¶"""
        if not detections:
            return []
        
        try:
            # æŒ‰ç½®ä¿¡åº¦æ’åº
            detections.sort(key=lambda x: x.confidence, reverse=True)
            
            # ç®€å•çš„NMSå®ç°
            filtered_detections = []
            
            for detection in detections:
                should_keep = True
                
                for kept_detection in filtered_detections:
                    iou = self._calculate_iou(detection.bbox, kept_detection.bbox)
                    if iou > iou_threshold:
                        should_keep = False
                        break
                
                if should_keep:
                    filtered_detections.append(detection)
            
            return filtered_detections
            
        except Exception as e:
            logger.error(f"NMSå¤„ç†å¤±è´¥: {e}")
            return detections
    
    def _calculate_iou(self, bbox1: List[float], bbox2: List[float]) -> float:
        """è®¡ç®—IoU"""
        try:
            x1_1, y1_1, x2_1, y2_1 = bbox1
            x1_2, y1_2, x2_2, y2_2 = bbox2
            
            # è®¡ç®—äº¤é›†
            x1_inter = max(x1_1, x1_2)
            y1_inter = max(y1_1, y1_2)
            x2_inter = min(x2_1, x2_2)
            y2_inter = min(y2_1, y2_2)
            
            if x2_inter <= x1_inter or y2_inter <= y1_inter:
                return 0.0
            
            inter_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)
            
            # è®¡ç®—å¹¶é›†
            area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
            area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
            union_area = area1 + area2 - inter_area
            
            return inter_area / union_area if union_area > 0 else 0.0
            
        except Exception:
            return 0.0
    
    def _update_tracking(self, detections: List[Detection]) -> List[Detection]:
        """æ›´æ–°ç›®æ ‡è·Ÿè¸ª"""
        try:
            # åŒ¹é…æ£€æµ‹ç»“æœä¸ç°æœ‰è·Ÿè¸ªå¯¹è±¡
            matched_detections = []
            unmatched_detections = detections.copy()
            
            for detection in detections:
                best_match_id = None
                best_distance = float('inf')
                
                detection_center = [
                    (detection.bbox[0] + detection.bbox[2]) / 2,
                    (detection.bbox[1] + detection.bbox[3]) / 2
                ]
                
                for track_id, tracked_obj in self.tracking_objects.items():
                    if tracked_obj.position_history:
                        last_position = tracked_obj.position_history[-1]
                        distance = np.sqrt(
                            (detection_center[0] - last_position[0]) ** 2 +
                            (detection_center[1] - last_position[1]) ** 2
                        )
                        
                        if distance < self.distance_threshold and distance < best_distance:
                            best_distance = distance
                            best_match_id = track_id
                
                if best_match_id is not None:
                    # æ›´æ–°ç°æœ‰è·Ÿè¸ªå¯¹è±¡
                    detection.track_id = best_match_id
                    self.tracking_objects[best_match_id].update(detection)
                    matched_detections.append(detection)
                    unmatched_detections.remove(detection)
            
            # ä¸ºæœªåŒ¹é…çš„æ£€æµ‹åˆ›å»ºæ–°çš„è·Ÿè¸ªå¯¹è±¡
            for detection in unmatched_detections:
                track_id = self.next_track_id
                self.next_track_id += 1
                
                detection.track_id = track_id
                tracked_obj = TrackedObject(track_id=track_id)
                tracked_obj.update(detection)
                self.tracking_objects[track_id] = tracked_obj
                matched_detections.append(detection)
            
            return matched_detections
            
        except Exception as e:
            logger.error(f"è·Ÿè¸ªæ›´æ–°å¤±è´¥: {e}")
            return detections
    
    def _get_cached_detections(self) -> List[Detection]:
        """è·å–ç¼“å­˜çš„æ£€æµ‹ç»“æœ"""
        cached_detections = []
        
        try:
            current_time = time.time()
            
            for tracked_obj in self.tracking_objects.values():
                if (current_time - tracked_obj.last_seen < 0.5 and 
                    tracked_obj.detections and 
                    tracked_obj.is_stable):
                    
                    # ä½¿ç”¨æœ€æ–°çš„æ£€æµ‹ç»“æœ
                    latest_detection = tracked_obj.detections[-1]
                    cached_detections.append(latest_detection)
            
            if cached_detections:
                self.performance_stats['cached_detections'] += len(cached_detections)
            
        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜æ£€æµ‹å¤±è´¥: {e}")
        
        return cached_detections
    
    def _update_performance_stats(self, detection_count: int, processing_time: float, success: bool):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        self.performance_stats['total_detections'] += 1
        
        if success:
            self.performance_stats['successful_detections'] += 1
        else:
            self.performance_stats['failed_detections'] += 1
        
        # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
        total_successful = self.performance_stats['successful_detections']
        if total_successful > 0:
            current_avg = self.performance_stats['avg_processing_time']
            self.performance_stats['avg_processing_time'] = (
                (current_avg * (total_successful - 1) + processing_time) / total_successful
            )
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        with self.lock:
            stats = self.performance_stats.copy()
            
            # æ·»åŠ æ¨¡å‹ç»Ÿè®¡
            model_stats = {}
            for model_name, model_config in self.models.items():
                model_stats[model_name] = {
                    'inference_count': model_config.inference_count,
                    'avg_inference_time': model_config.avg_inference_time,
                    'cache_size': len(model_config.result_cache),
                    'is_loaded': model_config.is_loaded
                }
            
            stats['models'] = model_stats
            stats['active_tracks'] = len(self.tracking_objects)
            
            return stats
    
    def clear_all_caches(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        with self.lock:
            for model_config in self.models.values():
                model_config.clear_cache()
            
            self.tracking_objects.clear()
            self.next_track_id = 1
            
            logger.info("æ‰€æœ‰ç¼“å­˜å·²æ¸…ç©º")
    
    def optimize_memory(self):
        """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        try:
            # æ¸…ç†è¿‡æœŸè·Ÿè¸ª
            self._cleanup_expired_tracks()
            
            # æ¸…ç†æ¨¡å‹ç¼“å­˜
            self._cleanup_model_caches()
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            
            logger.info("å†…å­˜ä¼˜åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"å†…å­˜ä¼˜åŒ–å¤±è´¥: {e}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        model_info = {}
        
        for model_name, model_config in self.models.items():
            model_info[model_name] = {
                'model_path': model_config.model_path,
                'model_type': model_config.model_type.value,
                'is_loaded': model_config.is_loaded,
                'load_time': model_config.load_time,
                'inference_count': model_config.inference_count,
                'avg_inference_time': model_config.avg_inference_time,
                'confidence_threshold': model_config.confidence_threshold,
                'iou_threshold': model_config.iou_threshold,
                'cache_enabled': model_config.enable_cache,
                'cache_size': len(model_config.result_cache)
            }
        
        return model_info


# å‘åå…¼å®¹çš„åˆ«å
MultiModelDetector = EnhancedMultiModelDetector


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    models_config = {
        "best.pt": "models/best.pt",
        "strawberry_yolov11.pt": "models/strawberry_yolov11.pt"
    }
    
    detector = EnhancedMultiModelDetector(models_config)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    model_info = detector.get_model_info()
    print("æ¨¡å‹ä¿¡æ¯:")
    for name, info in model_info.items():
        print(f"  {name}: {info}")
    
    # æ‰“å°æ€§èƒ½ç»Ÿè®¡
    stats = detector.get_performance_stats()
    print(f"\næ€§èƒ½ç»Ÿè®¡: {stats}")